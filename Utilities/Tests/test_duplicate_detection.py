#!/usr/bin/env python3
"""
Test script to verify duplicate detection is working properly
"""
import requests
import json
import sys
import os
from pathlib import Path

# Add ScrapeSystem to path
sys.path.append(str(Path(__file__).parent.parent.parent / "ScrapeSystem"))

def test_database_properties():
    """Test current database properties"""
    print("ğŸ§ª Testing Database Properties")
    print("=" * 40)
    
    try:
        response = requests.get("http://localhost:5000/api/property", timeout=10)
        if response.status_code == 200:
            properties = response.json()
            print(f"ğŸ“Š Database contains {len(properties)} properties")
            
            # Show sample properties
            for i, prop in enumerate(properties[:3]):
                print(f"   {i+1}. {prop.get('price', 'N/A')} - {prop.get('fullAddress', 'N/A')}")
                print(f"      URL: {prop.get('detailUrl', 'N/A')[:50]}...")
            
            return properties
        else:
            print(f"âŒ Database API returned status {response.status_code}")
            return []
    except requests.exceptions.RequestException as e:
        print(f"âŒ Cannot connect to database API: {e}")
        return []

def test_duplicate_detection():
    """Test the duplicate detection logic"""
    print("\nğŸ§ª Testing Duplicate Detection")
    print("=" * 40)
    
    try:
        from post_to_database import check_existing_properties, post_batch_properties
        
        # Get existing properties
        existing_properties = check_existing_properties()
        print(f"ğŸ“Š Found {len(existing_properties)} existing properties")
        
        # Create test data with one duplicate and one new property
        test_properties = [
            {
                "site": "landsearch",
                "address": "Test Property 1",
                "fullAddress": "123 Test St, Test City, KY",
                "price": "$100,000",
                "detailUrl": "https://test.com/property1"  # This should be new
            },
            {
                "site": "landsearch", 
                "address": "Test Property 2",
                "fullAddress": "456 Test St, Test City, KY",
                "price": "$200,000",
                "detailUrl": existing_properties[0].get('detailUrl', 'https://existing.com')  # This should be duplicate
            }
        ]
        
        print(f"ğŸ“¦ Testing with {len(test_properties)} properties (1 new, 1 duplicate)")
        
        # Test the duplicate detection
        result = post_batch_properties(test_properties)
        
        if result:
            print("âœ… Duplicate detection test completed")
            return True
        else:
            print("âŒ Duplicate detection test failed")
            return False
            
    except Exception as e:
        print(f"âŒ Error testing duplicate detection: {e}")
        import traceback
        traceback.print_exc()
        return False

def test_scraper_data_flow():
    """Test the complete scraper data flow"""
    print("\nğŸ§ª Testing Scraper Data Flow")
    print("=" * 40)
    
    try:
        from post_to_database import load_scraped_data
        
        # Load scraped data
        scraped_data = load_scraped_data()
        print(f"ğŸ“„ Loaded {len(scraped_data)} properties from cache")
        
        if scraped_data:
            print("ğŸ“‹ Sample scraped properties:")
            for i, prop in enumerate(scraped_data[:2]):
                print(f"   {i+1}. {prop.get('price', 'N/A')} - {prop.get('full_address', 'N/A')}")
                print(f"      URL: {prop.get('detail_url', 'N/A')[:50]}...")
            
            return True
        else:
            print("âŒ No scraped data found")
            return False
            
    except Exception as e:
        print(f"âŒ Error testing scraper data flow: {e}")
        return False

def main():
    """Main test function"""
    print("ğŸš€ Duplicate Detection Test Suite")
    print("=" * 50)
    
    # Change to project root
    project_root = Path(__file__).parent.parent.parent
    os.chdir(project_root)
    print(f"ğŸ“ Working directory: {os.getcwd()}")
    
    # Run tests
    db_ok = test_database_properties()
    duplicate_ok = test_duplicate_detection()
    scraper_ok = test_scraper_data_flow()
    
    print("\n" + "=" * 50)
    print("ğŸ“Š Test Results Summary:")
    print(f"   Database Connection: {'âœ…' if db_ok else 'âŒ'}")
    print(f"   Duplicate Detection: {'âœ…' if duplicate_ok else 'âŒ'}")
    print(f"   Scraper Data Flow: {'âœ…' if scraper_ok else 'âŒ'}")
    
    if all([db_ok, duplicate_ok, scraper_ok]):
        print("\nğŸ‰ All duplicate detection tests passed!")
        print("âœ… New scraped data should now be added to database")
    else:
        print("\nâŒ Some tests failed!")
        print("ğŸ’¡ Check the duplicate detection implementation")

if __name__ == "__main__":
    main()
